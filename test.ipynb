{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "NUM_CLASSES = 60\n",
    "LEARNING_RATE = 0.02\n",
    "MOMENTUM = 0.99\n",
    "WEIGHT_DECAY = 0.0005\n",
    "NUM_PRINT = 100\n",
    "LOG_DIR = './pth_file/densenet_model.pth'\n",
    "confirm_flag = True\n",
    "\n",
    "# 设置设备\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(edgeitems=10000)\n",
    "# 载入数据\n",
    "train_data = torchvision.datasets.ImageFolder(root='./Datasets/train', transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_data = torchvision.datasets.ImageFolder(root='./Datasets/test', transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "confirm_data = torchvision.datasets.ImageFolder(root='./Datasets/confirm', transform=transforms.ToTensor())\n",
    "confirm_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "# 定义网络模型\n",
    "# 定义conv_block\n",
    "def conv_block(in_channel, out_channel):\n",
    "    layer = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channel),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, bias=False)\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "\n",
    "# 定义dense_block\n",
    "class dense_block(nn.Module):\n",
    "    def __init__(self, in_channel, growth_rate, num_layers):\n",
    "        super(dense_block, self).__init__()\n",
    "        block = []\n",
    "        channel = in_channel\n",
    "        for i in range(num_layers):\n",
    "            block.append(conv_block(channel, growth_rate))\n",
    "            channel += growth_rate\n",
    "        self.net = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.net:\n",
    "            out = layer(x)\n",
    "            x = torch.cat((out, x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定义transition\n",
    "def transition(in_channel, out_channel):\n",
    "    trans_layer = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channel),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channel, out_channel, 1),\n",
    "        nn.AvgPool2d(2, 2)\n",
    "    )\n",
    "    return trans_layer\n",
    "\n",
    "\n",
    "# 定义densenet\n",
    "class densenet(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes, growth_rate=32, block_layers=[6, 12, 24, 16]):\n",
    "        super(densenet, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, 64, 7, 2, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3, 2, padding=1)\n",
    "        )\n",
    "        self.DB1 = self._make_dense_block(64, growth_rate, num=block_layers[0])\n",
    "        self.TL1 = self._make_transition_layer(256)\n",
    "        self.DB2 = self._make_dense_block(128, growth_rate, num=block_layers[1])\n",
    "        self.TL2 = self._make_transition_layer(512)\n",
    "        self.DB3 = self._make_dense_block(256, growth_rate, num=block_layers[2])\n",
    "        self.TL3 = self._make_transition_layer(1024)\n",
    "        self.DB4 = self._make_dense_block(512, growth_rate, num=block_layers[3])\n",
    "        self.global_average = nn.Sequential(\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "\n",
    "        x = self.DB1(x)\n",
    "        x = self.TL1(x)\n",
    "        x = self.DB2(x)\n",
    "        x = self.TL2(x)\n",
    "        x = self.DB3(x)\n",
    "        x = self.TL3(x)\n",
    "        x = self.DB4(x)\n",
    "\n",
    "        x = self.global_average(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _make_dense_block(self, channels, growth_rate, num):\n",
    "        block = []\n",
    "        block.append(dense_block(channels, growth_rate, num))\n",
    "        channels += num * growth_rate\n",
    "        return nn.Sequential(*block)\n",
    "\n",
    "    def _make_transition_layer(self, channels):\n",
    "        block = []\n",
    "        block.append(transition(channels, channels // 2))\n",
    "        return nn.Sequential(*block)\n",
    "\n",
    "\n",
    "# 定义Densenet来初始化densenet的输入通道和划分类别参数\n",
    "def Densenet(num_classes):\n",
    "    return densenet(in_channel=3, num_classes=num_classes)  # 输入数据通道数为in_channel=3\n",
    "\n",
    "\n",
    "# 初始化模型并将其移到目标设备上\n",
    "model = Densenet(NUM_CLASSES).to(DEVICE)\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    nesterov=True\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "# 定义get_cur_lr函数，用于存放lr(学习率)参数\n",
    "def get_cur_lr():\n",
    "    for param_group in optimizer.param_groups:  # optimizer.param_groups为数据字典\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "# 模型训练\n",
    "def train():\n",
    "    model.train()\n",
    "    record_train = list()\n",
    "    total, correct, train_loss = 0, 0, 0\n",
    "    start = time.time()\n",
    "\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)  # target.long()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total += target.size(0)\n",
    "        correct += (output.argmax(dim=1) == target).sum().item()\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        if (i + 1) % NUM_PRINT == 0:\n",
    "            print(\"step: [{}/{} ({:.0f}%)], train_loss: {:.3f} | train_acc: {:6.3f}% | lr: {:.6f}\"\n",
    "                  .format(i + 1, len(train_loader), NUM_PRINT * i / len(train_loader), train_loss / (i + 1),\n",
    "                          train_acc, get_cur_lr()))\n",
    "\n",
    "    print(\"--- cost time: {:.4f}s ---\".format(time.time() - start))\n",
    "\n",
    "    record_train.append(train_acc)\n",
    "\n",
    "    return record_train\n",
    "\n",
    "\n",
    "# 定义test函数用于测试数据集\n",
    "def test():\n",
    "    model.eval()\n",
    "    record_test = list()\n",
    "    total, correct = 0, 0\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        print(\"*************** test ***************\")\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.long())\n",
    "            total += target.size(0)\n",
    "            correct += (output.argmax(dim=1) == target).sum().item()\n",
    "            predict = nn.functional.softmax(output,dim = 1)\n",
    "    test_acc = 100.0 * correct / total\n",
    "\n",
    "    print(\"test_loss: {:.3f} | test_acc: {:6.3f}%\".format(loss.item(), test_acc))\n",
    "    print(\"************************************\\n\")\n",
    "    print(\"--- cost time: {:.4f}s ---\".format(time.time() - start))\n",
    "    record_test.append(test_acc)\n",
    "    \n",
    "    return record_test \n",
    "\n",
    "def confirm():\n",
    "    model.eval()\n",
    "    record_test = list()\n",
    "    total, correct =1, 0\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        print(\"*************** confirm ***************\")\n",
    "        for data, target in confirm_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            output = model(data)\n",
    "            predict = nn.functional.softmax(output,dim = 1)\n",
    "    test_acc = 100.0 * correct / total\n",
    "\n",
    "    print(predict)\n",
    "    record_test.append(test_acc)\n",
    "    \n",
    "    return record_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****验证模式*****\n",
      "*************** test ***************\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# 调用main函数\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     start_epoch \u001b[39m=\u001b[39m checkpoint[\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*****验证模式*****\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     confirm()\n\u001b[0;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[39m# 如果有保存的模型，则加载模型，并在其基础上继续训练\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(LOG_DIR):\n",
      "Cell \u001b[1;32mIn[11], line 210\u001b[0m, in \u001b[0;36mconfirm\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m         output \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m    209\u001b[0m         predict \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(output,dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 210\u001b[0m test_acc \u001b[39m=\u001b[39m \u001b[39m100.0\u001b[39;49m \u001b[39m*\u001b[39;49m correct \u001b[39m/\u001b[39;49m total\n\u001b[0;32m    212\u001b[0m \u001b[39mprint\u001b[39m(predict)\n\u001b[0;32m    213\u001b[0m record_test\u001b[39m.\u001b[39mappend(test_acc)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 如果test_flag=True,则加载已保存的模型\n",
    "    if confirm_flag:\n",
    "        # 加载保存的模型直接进行测试机验证，不进行此模块以后的步骤\n",
    "        checkpoint = torch.load(LOG_DIR)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        confirm()\n",
    "    else:\n",
    "        # 如果有保存的模型，则加载模型，并在其基础上继续训练\n",
    "        if os.path.exists(LOG_DIR):\n",
    "            checkpoint = torch.load(LOG_DIR)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            print('加载 epoch {} 成功！'.format(start_epoch))\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            print('无保存模型，将从头开始训练！')\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            print(\"========== epoch: [{}/{}] ==========\".format(epoch + 1 + start_epoch, start_epoch + EPOCHS))\n",
    "            train()\n",
    "            if lr_scheduler is not None:\n",
    "                lr_scheduler.step()\n",
    "            test()\n",
    "            # 保存模型\n",
    "            state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch + 1 + start_epoch}\n",
    "            torch.save(state, LOG_DIR)\n",
    "\n",
    "\n",
    "# 调用main函数\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
