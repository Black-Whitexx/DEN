{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262c05ee-8ce8-4826-a5f5-5f2a3e3e3131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2fc78a-d22f-4f01-a73e-929b64f22493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "NUM_CLASSES = 60\n",
    "LEARNING_RATE = 0.02\n",
    "MOMENTUM = 0.99\n",
    "WEIGHT_DECAY = 0.0005\n",
    "NUM_PRINT = 100\n",
    "LOG_DIR = './densenet121_model.pth'\n",
    "test_flag = False\n",
    "\n",
    "# 设置设备\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 载入数据\n",
    "train_data = torchvision.datasets.ImageFolder(root='./Datasets/train', transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_data = torchvision.datasets.ImageFolder(root='./Datasets/test', transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "# 定义网络模型\n",
    "# 定义conv_block\n",
    "def conv_block(in_channel, out_channel):\n",
    "    layer = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channel),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, bias=False)\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "\n",
    "# 定义dense_block\n",
    "class dense_block(nn.Module):\n",
    "    def __init__(self, in_channel, growth_rate, num_layers):\n",
    "        super(dense_block, self).__init__()\n",
    "        block = []\n",
    "        channel = in_channel\n",
    "        for i in range(num_layers):\n",
    "            block.append(conv_block(channel, growth_rate))\n",
    "            channel += growth_rate\n",
    "        self.net = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.net:\n",
    "            out = layer(x)\n",
    "            x = torch.cat((out, x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定义transition\n",
    "def transition(in_channel, out_channel):\n",
    "    trans_layer = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channel),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channel, out_channel, 1),\n",
    "        nn.AvgPool2d(2, 2)\n",
    "    )\n",
    "    return trans_layer\n",
    "\n",
    "\n",
    "# 定义densenet\n",
    "class densenet(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes, growth_rate=32, block_layers=[6, 12, 24, 16]):\n",
    "        super(densenet, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, 64, 7, 2, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3, 2, padding=1)\n",
    "        )\n",
    "        self.DB1 = self._make_dense_block(64, growth_rate, num=block_layers[0])\n",
    "        self.TL1 = self._make_transition_layer(256)\n",
    "        self.DB2 = self._make_dense_block(128, growth_rate, num=block_layers[1])\n",
    "        self.TL2 = self._make_transition_layer(512)\n",
    "        self.DB3 = self._make_dense_block(256, growth_rate, num=block_layers[2])\n",
    "        self.TL3 = self._make_transition_layer(1024)\n",
    "        self.DB4 = self._make_dense_block(512, growth_rate, num=block_layers[3])\n",
    "        self.global_average = nn.Sequential(\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.DB1(x)\n",
    "        x = self.TL1(x)\n",
    "        x = self.DB2(x)\n",
    "        x = self.TL2(x)\n",
    "        x = self.DB3(x)\n",
    "        x = self.TL3(x)\n",
    "        x = self.DB4(x)\n",
    "        x = self.global_average(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _make_dense_block(self, channels, growth_rate, num):\n",
    "        block = []\n",
    "        block.append(dense_block(channels, growth_rate, num))\n",
    "        channels += num * growth_rate\n",
    "        return nn.Sequential(*block)\n",
    "\n",
    "    def _make_transition_layer(self, channels):\n",
    "        block = []\n",
    "        block.append(transition(channels, channels // 2))\n",
    "        return nn.Sequential(*block)\n",
    "\n",
    "\n",
    "# 定义Densenet来初始化densenet的输入通道和划分类别参数\n",
    "def Densenet(num_classes):\n",
    "    return densenet(in_channel=3, num_classes=num_classes)  # 输入数据通道数为in_channel=3\n",
    "\n",
    "\n",
    "# 初始化模型并将其移到目标设备上\n",
    "model = Densenet(NUM_CLASSES).to(DEVICE)\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    nesterov=True\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "# 定义get_cur_lr函数，用于存放lr(学习率)参数\n",
    "def get_cur_lr():\n",
    "    for param_group in optimizer.param_groups:  # optimizer.param_groups为数据字典\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "# 模型训练\n",
    "def train():\n",
    "    model.train()\n",
    "    record_train = list()\n",
    "    total, correct, train_loss = 0, 0, 0\n",
    "    start = time.time()\n",
    "\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)  # target.long()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total += target.size(0)\n",
    "        correct += (output.argmax(dim=1) == target).sum().item()\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        if (i + 1) % NUM_PRINT == 0:\n",
    "            print(\"step: [{}/{} ({:.0f}%)], train_loss: {:.3f} | train_acc: {:6.3f}% | lr: {:.6f}\"\n",
    "                  .format(i + 1, len(train_loader), NUM_PRINT * i / len(train_loader), train_loss / (i + 1),\n",
    "                          train_acc, get_cur_lr()))\n",
    "\n",
    "    print(\"--- cost time: {:.4f}s ---\".format(time.time() - start))\n",
    "\n",
    "    record_train.append(train_acc)\n",
    "\n",
    "    return record_train\n",
    "\n",
    "\n",
    "# 定义test函数用于测试数据集\n",
    "def test():\n",
    "    model.eval()\n",
    "    record_test = list()\n",
    "    total, correct = 0, 0\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        print(\"*************** test ***************\")\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.long())\n",
    "            total += target.size(0)\n",
    "            correct += (output.argmax(dim=1) == target).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "\n",
    "    print(\"test_loss: {:.3f} | test_acc: {:6.3f}%\".format(loss.item(), test_acc))\n",
    "    print(\"************************************\\n\")\n",
    "    print(\"--- cost time: {:.4f}s ---\".format(time.time() - start))\n",
    "\n",
    "    record_test.append(test_acc)\n",
    "\n",
    "    return record_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e7592b-62b2-49d8-a51b-3ed808eaee05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无保存模型，将从头开始训练！\n",
      "========== epoch: [1/1] ==========\n",
      "step: [100/1527 (6%)], train_loss: 4.073 | train_acc:  4.750% | lr: 0.020000\n",
      "step: [200/1527 (13%)], train_loss: 3.905 | train_acc:  5.828% | lr: 0.020000\n",
      "step: [300/1527 (20%)], train_loss: 3.801 | train_acc:  6.292% | lr: 0.020000\n",
      "step: [400/1527 (26%)], train_loss: 3.702 | train_acc:  7.258% | lr: 0.020000\n",
      "step: [500/1527 (33%)], train_loss: 3.630 | train_acc:  7.944% | lr: 0.020000\n",
      "step: [600/1527 (39%)], train_loss: 3.554 | train_acc:  8.927% | lr: 0.020000\n",
      "step: [700/1527 (46%)], train_loss: 3.486 | train_acc: 10.045% | lr: 0.020000\n",
      "step: [800/1527 (52%)], train_loss: 3.420 | train_acc: 11.301% | lr: 0.020000\n",
      "step: [900/1527 (59%)], train_loss: 3.354 | train_acc: 12.562% | lr: 0.020000\n",
      "step: [1000/1527 (65%)], train_loss: 3.289 | train_acc: 13.756% | lr: 0.020000\n",
      "step: [1100/1527 (72%)], train_loss: 3.230 | train_acc: 14.903% | lr: 0.020000\n",
      "step: [1200/1527 (79%)], train_loss: 3.175 | train_acc: 15.990% | lr: 0.020000\n",
      "step: [1300/1527 (85%)], train_loss: 3.126 | train_acc: 16.981% | lr: 0.020000\n",
      "step: [1400/1527 (92%)], train_loss: 3.075 | train_acc: 17.982% | lr: 0.020000\n",
      "step: [1500/1527 (98%)], train_loss: 3.034 | train_acc: 18.856% | lr: 0.020000\n",
      "--- cost time: 129.4275s ---\n",
      "*************** test ***************\n",
      "test_loss: 3.673 | test_acc: 15.889%\n",
      "************************************\n",
      "\n",
      "--- cost time: 10.5826s ---\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model/densenet121_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 调用main函数\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 保存模型\u001b[39;00m\n\u001b[1;32m     31\u001b[0m state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m start_epoch}\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOG_DIR\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model/densenet121_model.pth'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 如果test_flag=True,则加载已保存的模型\n",
    "    if test_flag:\n",
    "        # 加载保存的模型直接进行测试机验证，不进行此模块以后的步骤\n",
    "        checkpoint = torch.load(LOG_DIR)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
    "        test()\n",
    "        return\n",
    "\n",
    "    # 如果有保存的模型，则加载模型，并在其基础上继续训练\n",
    "    if os.path.exists(LOG_DIR):\n",
    "        checkpoint = torch.load(LOG_DIR)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        print('无保存模型，将从头开始训练！')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"========== epoch: [{}/{}] ==========\".format(epoch + 1 + start_epoch, start_epoch + EPOCHS))\n",
    "        train()\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "        test()\n",
    "        # 保存模型\n",
    "        state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch + 1 + start_epoch}\n",
    "        torch.save(state, LOG_DIR)\n",
    "\n",
    "\n",
    "# 调用main函数\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6208f-6588-4b59-aabb-264cae3383cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
